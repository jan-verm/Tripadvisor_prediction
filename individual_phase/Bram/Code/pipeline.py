import data
import numpy as np
import operator
import os

from create_submission import write_predictions_to_csv
import utils

from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction import DictVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import FeatureUnion
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB
from sklearn import svm

# some global variables
KFOLD_SPLITS = 10
KFOLD_ITERATIONS = 10
LINEAR_MODEL_BASENAME = os.path.join('Predictions', 'linear_model')


class ItemSelector(BaseEstimator, TransformerMixin):
    """
    Part of the pipeline, used to select data generated by the Extractor.
    """
    def __init__(self, key):
        self.key = key

    def fit(self, x, y=None):
        return self

    def transform(self, data_dict):
        return data_dict[self.key]


class Extractor(BaseEstimator, TransformerMixin):
    """
    Extract some of the attributes from the list of reviews
    """
    def fit(self, x, y=None):
        return self

    def transform(self, reviews):
        features = np.recarray(shape=(len(reviews),),
                               dtype=[('content', object), ('review', object)])
        for i, review in enumerate(reviews):
            features['content'][i] = review.content
            features['review'][i] = review

        return features


class ReviewStats(BaseEstimator, TransformerMixin):
    """
    Extract and generate features from the list of reviews
    """
    def fit(self, x, y=None):
        return self

    def transform(self, reviews):
        return [{'length': len(review.content)
                 } for review in reviews]


def get_pipeline(parameter, classifier_type="lsvc"):
    """
    Create a pipeline for fitting and predicting, consisting of the different modules used for classification.

    :param parameter: The adjustable parameter for classification
    :param classifier_type: The type of classification
    :return: A pipeline object
    """
    pipeline_array = [
        ('features', Extractor()),
        ('union', FeatureUnion(
            transformer_list=[

                # Pipeline for standard bag-of-words model for content of review
                ('content', Pipeline([
                    ('selector', ItemSelector(key='content')),
                    ('tfidf', TfidfVectorizer(analyzer='word')),
                ])),

                # Pipeline for pulling ad hoc features from reviews
                ('review_features', Pipeline([
                    ('selector', ItemSelector(key='review')),
                    ('stats', ReviewStats()),  # returns a list of dicts
                    ('vect', DictVectorizer()),  # list of dicts -> feature matrix
                    ('scaled', StandardScaler(with_mean=False))
                ])),
            ],

            # weight components in FeatureUnion
            transformer_weights={
                'content': 1.0,
                'review_features': 1.0,
            },
        ))]

    if classifier_type == 'lsvc':
        pipeline_array.append(('clf', svm.LinearSVC(C=parameter)))
    elif classifier_type == 'mnb':
        pipeline_array.append(('clf', MultinomialNB(alpha=parameter)))
    elif classifier_type == 'bnb':
        pipeline_array.append(('clf', BernoulliNB()))
    elif classifier_type == 'gnb':
        pipeline_array.append(('clf', GaussianNB()))
    else:
        raise RuntimeError('Unavailable classifier type "{}", choose another one.'.format(classifier_type))

    return Pipeline(pipeline_array)


def cost_mae(y, y_hat):
    """
    The cost function (mae = Mean Absolute Error)
    :param y: True values
    :param y_hat: Predicted values
    :return: Cost value
    """
    y = np.array(y)
    y_hat = np.array(y_hat)
    mae = np.mean(np.abs(y - y_hat))

    return mae


def get_target(review_data):
    """
    Parse the ratings from a list of given Review objects
    """
    return [review.rating for review in review_data]


def learn(parameter=0.5, classification_type='lsvc', generate_submission=False):
    """
    The actual learning algorithm. There's support for an optional parameter and a choice between some classification
    methods.

    :param parameter: the adjustable parameter for the classification
    :param classification_type:
    :param generate_submission: boolean, generate a submission or not
    :return: cross validation score guess
    """
    data_set = data.load_pickled_data()
    train_data_set = data_set['train']
    pipeline = get_pipeline(parameter, classification_type)

    # k-fold cross validation, with k='KFOLD_SPLITS'
    kfold = KFold(n_splits=KFOLD_SPLITS, shuffle=True)
    i = 1
    total_mae = 0

    # execute 'KFOLD_ITERATIONS' times
    for train_idx, test_idx in kfold.split(train_data_set):
        test_data = operator.itemgetter(*test_idx)(train_data_set)
        train_data = operator.itemgetter(*train_idx)(train_data_set)

        pipeline.fit(train_data, get_target(train_data))
        prediction = pipeline.predict(test_data)

        mae = cost_mae(prediction, get_target(test_data))
        total_mae += mae

        if i == KFOLD_ITERATIONS:
            break

        i += 1

    # calculate the final score guess as the mean of the fold scores
    mean_score_guess = total_mae / KFOLD_ITERATIONS

    # create a csv file to submit on Kaggle
    if generate_submission:
        test_data_set = data_set['test']
        pipeline.fit(train_data_set, get_target(train_data_set))
        predicted_ratings = pipeline.predict(test_data_set)
        dump_predictions(predicted_ratings, mean_score_guess)

    # return the score calculated by cross validation
    return mean_score_guess


def dump_predictions(predicted_ratings, score_guess):
    """
    Dump the predictions to file with a unique name, including the guessed score.
    :param predicted_ratings: The final predictions made by the learning algorithm
    :param score_guess: The score calculated by cross validation
    """
    prediction_file_name = utils.generate_unqiue_file_name(
        LINEAR_MODEL_BASENAME, '{}.csv'.format(round(score_guess, 3) * 1000))
    write_predictions_to_csv(predicted_ratings, prediction_file_name)
    print 'Dumped predicted ratings to {}'.format(prediction_file_name)


if __name__ == '__main__':

    # optimal parameters
    c = 0.5
    classification_type = 'lsvc'

    # execute learn
    mae = learn(c, classification_type, True)
    print "Score = {}".format(mae)
